{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGN9Le3CfQ15"
      },
      "source": [
        "Set colab to access the images in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTQHjLcResfO",
        "outputId": "532dfbc9-dc56-4577-838d-826a6b02d223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjAuT2mS2jTj"
      },
      "source": [
        "## Image sample folder setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "93eP0Tbnhpzy",
        "outputId": "1ae21072-da01-4a9f-bd07-96ccba5cc978"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6d81fffd0473>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Ensure the destination folder exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "\n",
        "# Define the source and destination folders\n",
        "source_folder = '/content/drive/My Drive/RealData_resized'\n",
        "destination_folder = '/content/drive/My Drive/Sample/Real'\n",
        "\n",
        "# Ensure the destination folder exists\n",
        "if not os.path.exists(destination_folder):\n",
        "    os.makedirs(destination_folder)\n",
        "\n",
        "# Get the list of image files in the source folder\n",
        "image_files = [f for f in os.listdir(source_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Specify the number of images you want to copy\n",
        "number_of_images_to_copy = 600\n",
        "\n",
        "# Copy the specified number of images to the destination folder\n",
        "for i, image_file in enumerate(image_files):\n",
        "    if i < number_of_images_to_copy:\n",
        "        source_path = os.path.join(source_folder, image_file)\n",
        "        destination_path = os.path.join(destination_folder, image_file)\n",
        "        shutil.copy(source_path, destination_path)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(f'Copied {number_of_images_to_copy} images to {destination_folder}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TGYQ1KFFrd-O"
      },
      "outputs": [],
      "source": [
        "num_files = len([f for f in os.listdir(destination_folder) if os.path.isfile(os.path.join(destination_folder, f))])\n",
        "\n",
        "print(f'There are {num_files} files in the folder.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9gdcGp42rTm"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHSKcdoQfWbc"
      },
      "source": [
        "Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsAiLTQ-jMZO"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FJ0MkfTNfOS5"
      },
      "outputs": [],
      "source": [
        "import os   # To navigate into the drive folders and access the images\n",
        "import matplotlib.pyplot as plt   # To make plots\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator  # To process images in batches and apply transformations\n",
        "from keras.applications import VGG19   # Import the VGG19 model\n",
        "from keras.models import Sequential    # Allow us to add another layer to the pretrained model that makes the classification\n",
        "from keras.layers import Flatten, Dense, Dropout   # Flatten the output layer to make it able for input in the Dense layer\n",
        "from keras.optimizers import Adam    # Import the Adam optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZxQLSF-hnZM"
      },
      "source": [
        "Defining paths to our images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l3Y8CkA63Bfh"
      },
      "outputs": [],
      "source": [
        "# Define the base directory where your 'sample' folder is located\n",
        "base_dir = '/content/drive/My Drive/Sample'\n",
        "\n",
        "# Define the paths to the training, validation, and testing directories\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTGofGXG_PV9"
      },
      "source": [
        "Data normalization and ImageDataGenerator instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jtgP1QY_R8t",
        "outputId": "0c882a3a-9570-4380-e520-d05baad2c3ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Rescale the pixel values from [0, 255] to [0, 1] for normalization\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen  = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen  = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224,224),   # This is the input size required for the VGG19 model\n",
        "    batch_size=20,  # It will be iterating from batches of 20 images\n",
        "    class_mode= 'binary'  # Label the images in a binary way (Fake or Real)\n",
        ")\n",
        "\n",
        "Validation_generator = validation_datagen .flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(224,224),   # This is the input size required for the VGG19 model\n",
        "    batch_size=20,  # It will be iterating from batches of 20 images\n",
        "    class_mode= 'binary'  # Label the images in a binary way (Fake or Real)\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224,224),   # This is the input size required for the VGG19 model\n",
        "    batch_size=20,  # It will be iterating from batches of 20 images\n",
        "    class_mode= 'binary',  # Label the images in a binary way (Fake or Real)\n",
        "    shuffle=False)  # No need to shuffle the test data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the VGG19 model pre-trained on ImageNet, excluding its top (fully connected) layers\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the base model to prevent them from being updated during training\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new Sequential model and add the VGG19 base model without dropout\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),  # Flatten the output of the base model to a 1D vector\n",
        "    Dense(256, activation='relu'),  # Add a fully connected layer with 256 units and ReLU activation\n",
        "    Dropout(0.4),  # Add dropout for regularization (reduce overfitting)\n",
        "    Dense(1, activation='sigmoid')  # Add the output layer with sigmoid activation for binary classification\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irK_S_wPHJ9Z",
        "outputId": "27aabd9d-46d6-43c8-8825-511d8cf3ad97"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compilation with Adam activation and binary_crossentropy loss function, good for binary classifications\n",
        "# Metrics also included\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate= 1e-4),\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy', 'Precision', 'Recall'])"
      ],
      "metadata": {
        "id": "74iUW1KuHShA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First model training"
      ],
      "metadata": {
        "id": "VprAvkO-TMIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "num_epochs = 10\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch= 40,   # Batch size is 20, 20 times 40 is 800, the size of the training data\n",
        "    epochs=num_epochs,\n",
        "    validation_data=Validation_generator,\n",
        "    validation_steps = 5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucTg0xYPK4tT",
        "outputId": "57e9e0e7-918d-474a-e7e4-4c2861436659"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 200s 5s/step - loss: 0.7005 - accuracy: 0.6313 - precision: 0.6290 - recall: 0.6400 - val_loss: 0.4985 - val_accuracy: 0.7300 - val_precision: 0.7442 - val_recall: 0.6667\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 37s 945ms/step - loss: 0.4283 - accuracy: 0.8163 - precision: 0.8286 - recall: 0.7975 - val_loss: 0.4505 - val_accuracy: 0.8200 - val_precision: 0.7500 - val_recall: 0.9130\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 27s 683ms/step - loss: 0.3217 - accuracy: 0.8625 - precision: 0.8756 - recall: 0.8450 - val_loss: 0.4446 - val_accuracy: 0.7900 - val_precision: 0.7333 - val_recall: 0.8980\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 23s 568ms/step - loss: 0.2740 - accuracy: 0.8963 - precision: 0.8972 - recall: 0.8950 - val_loss: 0.3783 - val_accuracy: 0.8500 - val_precision: 0.8511 - val_recall: 0.8333\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 21s 521ms/step - loss: 0.1984 - accuracy: 0.9350 - precision: 0.9328 - recall: 0.9375 - val_loss: 0.3914 - val_accuracy: 0.8400 - val_precision: 0.8409 - val_recall: 0.8043\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 20s 487ms/step - loss: 0.1739 - accuracy: 0.9488 - precision: 0.9614 - recall: 0.9350 - val_loss: 0.3084 - val_accuracy: 0.8300 - val_precision: 0.8636 - val_recall: 0.7755\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 20s 503ms/step - loss: 0.1422 - accuracy: 0.9638 - precision: 0.9720 - recall: 0.9550 - val_loss: 0.3186 - val_accuracy: 0.8700 - val_precision: 0.9512 - val_recall: 0.7800\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 19s 477ms/step - loss: 0.1114 - accuracy: 0.9750 - precision: 0.9822 - recall: 0.9675 - val_loss: 0.2682 - val_accuracy: 0.9000 - val_precision: 0.8929 - val_recall: 0.9259\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 20s 492ms/step - loss: 0.1056 - accuracy: 0.9762 - precision: 0.9798 - recall: 0.9725 - val_loss: 0.3869 - val_accuracy: 0.8100 - val_precision: 0.7759 - val_recall: 0.8824\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 20s 492ms/step - loss: 0.0850 - accuracy: 0.9850 - precision: 0.9899 - recall: 0.9800 - val_loss: 0.3809 - val_accuracy: 0.7900 - val_precision: 0.7955 - val_recall: 0.7447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's performance on the test set\n",
        "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_generator)\n",
        "print('Test accuracy:', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gpiJGSHQ399",
        "outputId": "9ce22eb3-1841-4fac-cf7d-fb00f01282a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 4s 367ms/step - loss: 0.3322 - accuracy: 0.8350 - precision: 0.8764 - recall: 0.7800\n",
            "Test accuracy: 0.8349999785423279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the results, we se that 8 epochs is the optimal number of epochs to get the best results, we are making a second model increasing the dropout and setting just 8 epochs. Remember that it is working with sample data"
      ],
      "metadata": {
        "id": "AJx0zfHcTQOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the layers of the base model to prevent them from being updated during training\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),  # Flatten the output of the base model to a 1D vector\n",
        "    Dense(256, activation='relu'),  # Add a fully connected layer with 256 units and ReLU activation\n",
        "    Dropout(0.5),  # Add dropout for regularization (reduce overfitting)\n",
        "    Dense(1, activation='sigmoid')  # Add the output layer with sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "# Model compilation with Adam activation and binary_crossentropy loss function, good for binary classifications\n",
        "# Metrics also included\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate= 1e-4),\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "# Model training\n",
        "num_epochs = 8\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch= 40,   # Batch size is 20, 20 times 40 is 800, the size of the training data\n",
        "    epochs=num_epochs,\n",
        "    validation_data=Validation_generator,\n",
        "    validation_steps = 5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXyZ1w8hTc9x",
        "outputId": "7d5c4573-a338-4bdd-ff70-54cb4aeaa939"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "40/40 [==============================] - 22s 504ms/step - loss: 0.6923 - accuracy: 0.6250 - precision: 0.6269 - recall: 0.6175 - val_loss: 0.5549 - val_accuracy: 0.7200 - val_precision: 0.6885 - val_recall: 0.8235\n",
            "Epoch 2/8\n",
            "40/40 [==============================] - 20s 498ms/step - loss: 0.4644 - accuracy: 0.7800 - precision: 0.7800 - recall: 0.7800 - val_loss: 0.4893 - val_accuracy: 0.7700 - val_precision: 0.7213 - val_recall: 0.8800\n",
            "Epoch 3/8\n",
            "40/40 [==============================] - 19s 479ms/step - loss: 0.3686 - accuracy: 0.8487 - precision: 0.8642 - recall: 0.8275 - val_loss: 0.4695 - val_accuracy: 0.8000 - val_precision: 0.7377 - val_recall: 0.9184\n",
            "Epoch 4/8\n",
            "40/40 [==============================] - 22s 559ms/step - loss: 0.2799 - accuracy: 0.8950 - precision: 0.8990 - recall: 0.8900 - val_loss: 0.4053 - val_accuracy: 0.8300 - val_precision: 0.8077 - val_recall: 0.8571\n",
            "Epoch 5/8\n",
            "40/40 [==============================] - 19s 484ms/step - loss: 0.2281 - accuracy: 0.9262 - precision: 0.9383 - recall: 0.9125 - val_loss: 0.3643 - val_accuracy: 0.8500 - val_precision: 0.8409 - val_recall: 0.8222\n",
            "Epoch 6/8\n",
            "40/40 [==============================] - 20s 496ms/step - loss: 0.2143 - accuracy: 0.9237 - precision: 0.9270 - recall: 0.9200 - val_loss: 0.3565 - val_accuracy: 0.8600 - val_precision: 0.8837 - val_recall: 0.8085\n",
            "Epoch 7/8\n",
            "40/40 [==============================] - 19s 489ms/step - loss: 0.1750 - accuracy: 0.9538 - precision: 0.9572 - recall: 0.9500 - val_loss: 0.3832 - val_accuracy: 0.8300 - val_precision: 0.8571 - val_recall: 0.8077\n",
            "Epoch 8/8\n",
            "40/40 [==============================] - 20s 495ms/step - loss: 0.1341 - accuracy: 0.9675 - precision: 0.9795 - recall: 0.9550 - val_loss: 0.3641 - val_accuracy: 0.8400 - val_precision: 0.8269 - val_recall: 0.8600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's performance on the test set\n",
        "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_generator)\n",
        "print('Test accuracy:', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7EJu5LVVCv8",
        "outputId": "6405d200-5392-46dc-f6a7-60927b64288a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 5s 416ms/step - loss: 0.3643 - accuracy: 0.8300 - precision: 0.8235 - recall: 0.8400\n",
            "Test accuracy: 0.8299999833106995\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jjAuT2mS2jTj"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}