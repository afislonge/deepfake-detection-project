{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV1YGdPG8yp2",
        "outputId": "173542d0-c33f-4753-8a2c-695f8ebc1c7a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LekP22DquVhr"
      },
      "outputs": [],
      "source": [
        "# Importing all the necessary modules for Deepfake detection\n",
        "from builtins import range, input\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import Input, Lambda\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Data\n",
        "image_data = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/CT')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukGvVTHrukBd",
        "outputId": "c23c2d2e-e563-4f00-c317-945362ab9a54"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8054 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing a numpy iterator for the image_data dataset\n",
        "data_iterator = image_data.as_numpy_iterator()\n",
        "# Get the next batch of images  from the iterator\n",
        "batch = data_iterator.next()\n",
        "# Check the batch size\n",
        "batch_size = batch.shape[0]\n",
        "print(f\"Batch size: {batch_size}\")"
      ],
      "metadata": {
        "id": "hLFYvtMfwRMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at  images from dataset\n",
        "fig, ax = plt.subplots(ncols=4,nrows=4, figsize=(24,24))\n",
        "for idx, img in enumerate(batch[0][:7]):\n",
        "    ax[idx].imshow(img.astype(int))\n",
        "    ax[idx].title.set_text(batch[1][idx])"
      ],
      "metadata": {
        "id": "2vV8XpQ3xF3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data for training, validation and testing\n",
        "import random\n",
        "img_training = int(0.7 * len(image_data))\n",
        "img_validation = int(0.15 * len(image_data))\n",
        "img_testing = int(0.15 * len(image_data))\n",
        "\n",
        "# Randomly shuffling the images\n",
        "random.shuffle(image_data)\n",
        "\n",
        "# Split the dataset into training, validation, and testing sets\n",
        "train = image_data[:img_training]\n",
        "val = image_data[img_training:img_training+img_validation]\n",
        "test = image_data[img_training+img_validation:]"
      ],
      "metadata": {
        "id": "WOErD29QyCU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building CNN Model\n",
        "model =Sequential()"
      ],
      "metadata": {
        "id": "f2bprI9P0hcf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional Layer1\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "\n",
        "# Max Pooling Layer1\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Convolutional Layer2\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Max Pooling Layer2\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Convolutional Layer3\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "\n",
        "# Max Pooling Layer3\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Convolutional Layer4\n",
        "model.add(Conv2D(256, (5, 5), activation='relu'))\n",
        "\n",
        "# Max Pooling Layer4\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten Layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer1\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# Dropout Layer\n",
        "model.add(Dropout(0.5))\n",
        "# Dense Layer2\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Dropout layer\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "AYXCOwtH2CfN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qeJrjA3y4Yvw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sno4yYXV7sVt",
        "outputId": "b118cd45-422c-4ac9-feb5-30d293caa43d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 256)       819456    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 13, 13, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 43264)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               22151680  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23195969 (88.49 MB)\n",
            "Trainable params: 23195969 (88.49 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}